{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "HIDDEN_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.df = pd.read_csv(data_path)\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.bow_features = self.vectorizer.fit_transform(self.df[\"text\"]).toarray()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.df[\"intent\"])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        bow_features = torch.tensor(self.bow_features[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return bow_features, label\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_encoder.classes_\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        vocab_size = len(self.vectorizer.vocabulary_)\n",
    "        return vocab_size\n",
    "    \n",
    "    def get_num_classes(self):\n",
    "        return len(self.label_encoder.classes_)\n",
    "    \n",
    "    def label2id(self, label):\n",
    "        return self.label_encoder.classes_[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'train_path': 'data/train',\n",
       "  'val_path': 'data/val',\n",
       "  'batch_size': 8,\n",
       "  'num_workers': 1},\n",
       " 'model': {'hidden_size': 8, 'dropout': 0.2},\n",
       " 'training': {'epochs': 10,\n",
       "  'learning_rate': 0.001,\n",
       "  'device': 'cpu',\n",
       "  'save_dir': 'checkpoints'},\n",
       " 'logging': {'log_dir': 'logs', 'experiment_name': 'ann_classification'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "def load_config(config_path: str) -> dict:\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "load_config(\"../config/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train code\n",
    "def train_epoch(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        logits = model(data)\n",
    "        \n",
    "        loss = criterion(logits, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        pred_label = logits.softmax(-1).argmax(-1) # [batch_size label]\n",
    "        \n",
    "        _, predicted = logits.max(1) # [same as above]\n",
    "        # print(\"*******************************\")\n",
    "        # print(logits)\n",
    "        # print(\"======================================\")\n",
    "        # print(logits.max(1))\n",
    "        # print(\"***********************************\")\n",
    "        # print(pred_label)\n",
    "        # print(\"-------------------------------------------\")\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "    return total_loss / total, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        print(f\"Epoch {epoch} | Loss {train_loss} | Accuracy {train_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Model\n",
    "\n",
    "class TextClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.layer_1 = torch.nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        self.layer_2 = torch.nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "        self.layer_3 = torch.nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.relu(self.layer_1(X))\n",
    "        X = self.relu(self.layer_2(X))\n",
    "        X = self.layer_3(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(\"../data/train.csv\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassifier(\n",
    "    # bow feature size will be the input size here\n",
    "    input_size=train_dataset.get_vocab_size(),\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_classes=train_dataset.get_num_classes()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (layer_1): Linear(in_features=70, out_features=16, bias=True)\n",
       "  (layer_2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (layer_3): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss 0.317097544670105 | Accuracy 0.35294117647058826\n",
      "Epoch 1 | Loss 0.3157257227336659 | Accuracy 0.35294117647058826\n",
      "Epoch 2 | Loss 0.3148645232705509 | Accuracy 0.35294117647058826\n",
      "Epoch 3 | Loss 0.31375794901567344 | Accuracy 0.35294117647058826\n",
      "Epoch 4 | Loss 0.32749736309051514 | Accuracy 0.35294117647058826\n",
      "Epoch 5 | Loss 0.32623359035043153 | Accuracy 0.35294117647058826\n",
      "Epoch 6 | Loss 0.324672635863809 | Accuracy 0.35294117647058826\n",
      "Epoch 7 | Loss 0.30921011461931114 | Accuracy 0.35294117647058826\n",
      "Epoch 8 | Loss 0.31990691844154806 | Accuracy 0.35294117647058826\n",
      "Epoch 9 | Loss 0.3073955563937916 | Accuracy 0.35294117647058826\n",
      "Epoch 10 | Loss 0.316697779823752 | Accuracy 0.35294117647058826\n",
      "Epoch 11 | Loss 0.3056673863354851 | Accuracy 0.35294117647058826\n",
      "Epoch 12 | Loss 0.3153080484446357 | Accuracy 0.35294117647058826\n",
      "Epoch 13 | Loss 0.31132567279479084 | Accuracy 0.35294117647058826\n",
      "Epoch 14 | Loss 0.300165081725401 | Accuracy 0.35294117647058826\n",
      "Epoch 15 | Loss 0.3053232992396635 | Accuracy 0.4117647058823529\n",
      "Epoch 16 | Loss 0.2944750119658077 | Accuracy 0.4117647058823529\n",
      "Epoch 17 | Loss 0.2923299705280977 | Accuracy 0.47058823529411764\n",
      "Epoch 18 | Loss 0.28582532966838164 | Accuracy 0.5294117647058824\n",
      "Epoch 19 | Loss 0.28626568527782664 | Accuracy 0.5882352941176471\n",
      "Epoch 20 | Loss 0.2793503964648527 | Accuracy 0.5882352941176471\n",
      "Epoch 21 | Loss 0.274771090816049 | Accuracy 0.5882352941176471\n",
      "Epoch 22 | Loss 0.2631801261621363 | Accuracy 0.7058823529411765\n",
      "Epoch 23 | Loss 0.27086129258660707 | Accuracy 0.7647058823529411\n",
      "Epoch 24 | Loss 0.25472912718268004 | Accuracy 0.7647058823529411\n",
      "Epoch 25 | Loss 0.2542404672678779 | Accuracy 0.7647058823529411\n",
      "Epoch 26 | Loss 0.24163723693174474 | Accuracy 0.8823529411764706\n",
      "Epoch 27 | Loss 0.24023783206939697 | Accuracy 0.8823529411764706\n",
      "Epoch 28 | Loss 0.22307057240430048 | Accuracy 0.8823529411764706\n",
      "Epoch 29 | Loss 0.2269125265233657 | Accuracy 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
